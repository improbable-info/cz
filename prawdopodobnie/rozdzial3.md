## III. Co to je informace?

Shodně s tím, co jsme si pověděli v předchozí kapitole, každá definice bude neúplná a nepřesná.
Kromě toho v různých oblastech lidské činnosti se využívá různých aspektů informace,
což vyžaduje různé způsoby jejího definování. Takže se nebudeme snažit podat přesnou definici,
ale pokusme se nejdříve zamyslet, v jakých situacích to slovo používáme nejčastěji:
jestliže se chceme dovědět něco nového, nebo někomu něco sdělit, uchovat nějaké údaje, obdržet nějakou zprávu.
Ale používá se též například ve spojení "vznik biologické informace", nebo "informace obsažená v genech".
V matematickém přístupu se chápe jako poznatek, který omezuje nebo odstraňuje nejistotu
týkající se výskytu určitého jevu z dané množiny možných jevů. Někdy se informace chápe jako obsah zprávy,
kterou někdo někomu sděluje a zdůrazňuje se význam příjemce informace.
V podstatě můžeme všechny přístupy rozdělit do tří skupin: v první chápeme informaci jako něco,
co je obsažené ve zdroji informace (jako nějaká struktura, míra uspořádání nebo proces v něm probíhající),
ve druhé jako korelaci mezi dvěma strukturami a ve třetí vyžadujeme příjemce informace, pro kterého je určena.
Jestliže  přijmeme nějakou definici z jedné skupiny a používáme ji v situaci, která odpovídá jiné skupině,
můžeme dostat nelogická až nesrozumitelná tvrzení, což se bohužel občas stává.
A to například již v situaci, kdy chceme měřit informaci.
...
<!--Jako jednotka informace se uvádí jeden bit. Ale jaké je to množství informace?
Jestliže přijmeme stanovisko, že informace je to, co zmenšuje nevědomost příjemce informace,
pak jeden bit je takové množství informace, které zmenšuje tuto nevědomost o polovinu.
Můžeme si to znázornit na příkladu určení jednoho konkrétního pole na šachovnici.
První bit může například obsahovat informaci o tom, v které polovině šachovnice je vybrané pole,
čili vyloučí 32 polí z 64 možných. Zmenší naši nevědomost o polovinu.
Druhý bit může obsahovat informaci o tom, ve které polovině z dříve vybrané poloviny šachovnice je dané pole,
čili z 32 polí vyloučí dalších 16 polí, čili znovu zmenší naší nevědomost o polovinu.
Tak postupujeme dále, každý následující bit  zmenšuje počet možných polí o polovinu,
až konečně šestý bit vyloučí 1 pole ze 2 možných (znovu zmenší naši nevědomost o polovinu)
a jednoznačně již určuje konkrétní pole.

Je to jedna z možných definic jednoho bitu, která se ale hodí pouze pro třetí skupinu definice informace,
kde předpokládáme příjemce informace. Navíc zde musíme předpokládat,
že příjemce informace již určitou informaci má a potřebuje ji doplnit.

Často se uvádí definice, že 1 bit je takové množství informace,
které se dá vyjádřit v dvojkové soustavě pomocí nuly nebo jedničky.
Abychom ale mohli tuto nulu nebo jedničku využít, potřebujeme další informaci, co tato nula nebo jednička znamená.
Takže takto definovaný bit nemusí být identický s bitem podle první definice.

Dále je třeba si uvědomit, jak důležitá je pozice daného bitu.
Jestliže místo na Zemi bude určeno s přesností vyžadující 100 bitů, pak první bit může určovat,
zda jde o severní nebo jižní polokouli, a poslední bit rozlišovat dva body těsně vedle sebe.
Jestliže binární zápis pozice dvou bodů se bude lišit jen jedním bitem, může druhý bod ležet těsně vedle prvního,
ale může též ležet na opačné straně zeměkoule.

Podobně jestliže dva geny se shodují v 97 procentech, to samo o sobě neznamená, že jsou si blízké.
Jestliže vezmeme všechna čísla mezi nulou a jedničkou, která se dají zapsat pomocí sta cifer po desetinné čárce,
pak dvě taková čísla, která se budou shodovat v 97 místech od konce a jedno bude mít na začátku za desetinnou čárkou tři nuly
a druhé tři devítky, budou od sebe hodně vzdálená. Mnohem blíže si budou dvě čísla,
která se budou  shodovat pouze v prvních třech číslicích po desetinné čárce, čili pouze v 3 procentech.

Zamysleme se nyní nad tím, jak určit množství informace obsažené v nějakém jevu,
jestliže vezmeme nejobecnější definici informace jako míru uspořádanosti systému.
Mohlo by se zdát, že daný zdroj informace obsahuje určité množství informace nezávisle nejen na příjemci,
ale i na svém okolí. Když se nad tím zamyslíme, začnou se ale objevovat problémy.
Kolik informace je například v dopise s ručně napsaným textem: „Zítra bude padat sníh“?

Jestliže příjemce tohoto dopisu ví všechno kromě jediné věci: zda zítra bude nebo nebude padat sníh,
pak pro něj tento list má informační hodnotu jednoho bitu.

Jestliže list bude někdo zkoumat z hlediska, jaká je pravděpodobnost daného textu,
vyjde mu jiné množství informace v zimě a jiné v létě, jiné na severu a jiné v okolí rovníku.

Jestliže někoho zajímá jenom to, kolik potřebuje nul a jedniček, aby podaný text zapsal v počítači,
vyjde mu, že stačí okolo 150 bitů.

Ale informace je v dopise mnohem víc. Pokud jej bude zkoumat grafolog, bude jej zajímat tvar každé litery
i změny tloušťky linie. Kriminalisté mohou zkoumat chemické složení inkoustu, strukturu a stáří papíru,
otisky prstů atd. Mohli bychom pokračovat prakticky do nekonečna.

Kolik informace je tedy obsaženo v daném dopise? Jedna z možností je přijmout stanovisko,
že množství informace záleží na příjemci informace a jeho vědomostech.
To ale jednak zúžuje pojem informace jen do naší třetí definice, a i tak tu zůstávají nejasnosti,
jak to je s množstvím informace po přečtení dopisu, kdy už se nevědomost příjemce informace zmenšila,
a co se stane, když to znovu zapomene. Zároveň je vidět, že stejný zdroj může dávat různé množství informace
různým příjemcům v závislosti na tom, co vědí a co je zajímá. Pokud nás zajímá informace v tom nejobecnějším smyslu,
jako sama struktura nebo jev, pak nám tato definice nevyhovuje. Než se ale pokusíme najít nějaké lepší řešení,
uveďme ještě jeden příklad: V nepřehledném terénu se pohybuje osoba, která má signalizační pistoli s jedním nábojem.
V případě nouze vystřelí vzhůru nad sebe a tím dá signál záchranné skupině, aby ji šla hledat.
Otázka zní: Kolik informace je obsaženo v takovém signálu? Sám výstřel je možné považovat za jeden bit.
Ale záchranná skupina se dozví ještě mnohem víc, a sice polohu odkud bylo vystřeleno.
Kolik bitů informace? To záleží na tom, jak přesně jsou schopni měřit úhel.
Může to být jen několik bitů, ale  mohou to být (alespoň teoreticky) i stovky bitů.

Přijmeme proto stanovisko, že informace nemusí být závislá na příjemci,
ale její množství musíme měřit vždy v rámci určitého modelu, ve kterém je určena míra podrobností,
které budou rozlišovány a je dán kontext, ve kterém informaci zkoumáme.

Pro naše potřeby samu strukturu nebudeme ještě považovat za informaci, pouze za zdroj informace.
A o informaci budeme mluvit tehdy, jestliže nějaká jiná struktura nebo jev je v korelaci se zdrojem informace,
takže na základě této druhé struktury nebo jevu se dá usuzovat o vlastnostech zdroje informace.
Například: jestliže dojde k rozdělení genu, nový gen obsahuje informace o původním genu;
kruhy na pařezu obsahují informaci o stáří skáceného stromu. Světlo letící k nám z daleké hvězdy
nese nějakou informaci o této hvězdě.

Je nutné si ale uvědomit, že při této definici každá informace je nejistá, protože nikdy nemáme jistotu,
že to, co se dovídáme o jednom jevu prostřednictvím jiného jevu, je pravda.
Odkud víme, že daný signál znamená to, co si myslíme, že znamená? Je to jenom naše zkušenost, která je vždy neúplná.
To, že daná příčina má konkrétní následek, vyplývá jen z našeho modelu světa, který jsme přijali a považujeme za správný.

Abychom si trochu ujasnili, jaký je vztah mezi tím, co vidíme, co bychom mohli vidět, co si myslíme, že je, 
a tím co je ve skutečnosti, zamysleme se nad tím, jak vidíme hvězdy a souhvězdí.

Slunce vidíme tak, jak vypadalo před zhruba osmi minutami, další nejbližší hvězdu tak, jak vypadala před čtyřmi lety,
a nejvzdálenější hvězdy vidíme tam, kde byly před mnoha miliony let a teď jsou již úplně jinde a nebo již vůbec neexistují.
Souhvězdí, která vidíme na nebi, jsou výsledkem poskládání různě starých signálů, které spolu vůbec nesouvisí.
Kdyby se světlo šířilo jinou rychlostí anebo kdybychom hvězdy vnímaly prostřednictvím nějakého pomalejšího záření,
viděli bychom každou hvězdu úplně jinde a na nebi by byla úplně jiná souhvězdí.
A odkud víme, že hvězdy jsou někde jinde, než kde je vidíme? Je to výsledek našeho modelu světa,
který jsme si utvořili na základě našich dosavadních zkušeností. Víme, že hvězdy se pohybují a známe i zákonitosti,
kterými se tento pohyb řídí, umíme určit jak daleko jsou od nás a jak dlouho k nám letí jejich světlo.
Z toho všeho jsme schopni vypočíst, kde daná hvězda by měla být v této chvíli. Ale je tam skutečně?
Pravděpodobně není. Protože nejsme schopni přesně vypočíst všechny gravitační vlivy působící jednak na hvězdu,
a jednak na světlo, které od ní letí k nám. Kromě toho náš model světa a zákonitosti, které známe,
jsou též pouze jistým přiblížením skutečnosti. Ještě před sto i pár lety nikdo netušil,
že dráha světla se v gravitačním poli zakřivuje a za sto let mohou být odhaleny zákonitosti, o kterých dnes nemáme ponětí.

Mezi různými strukturami a jevy jsou složité závislosti, které zatím neznáme.
Ale podle naší definice je v těchto závislostech obsažená informace, kterou můžeme odhalit.

Ale vraťme se nyní k počítačům. Co je to informace z hlediska počítače?
V současných počítačích jsou zapsány řetězce nul a jedniček, čili nějaké struktury, které obsahují informaci tehdy
(podle naší definice), pokud jsou v nějakém vztahu k nějakým jiným strukturám nebo jevům.
Množství informace obsažené v nějakém řetězci nul a jedniček nemusí odpovídat jejich počtu
(prakticky vždy je počet použitých nul a jedniček mnohonásobně vyšší než by bylo nutné).
Počítač může informaci nejen přechovávat, vyhledávat a předávat, ale i přetvářet a zpracovávat,
a dokonce může z daných informací získávat novou informaci. Tu je třeba se zastavit a zamyslet,
jak vlastně může počítač utvořit novou informaci. Někdy se jeho možnosti přeceňují.
Musíme rozlišit dvě situace: jednak kdy množina nul a jedniček odpovídá nějakému vnějšímu objektu,
a druhá možnost, že odpovídá jiné množině nul a jedniček v počítači.

V prvém případě informace o objektu je zapsána s určitou úrovní podrobností,
která byla zvolena na vstupu (není možné v počítači utvořit obraz nějakého reálného objektu úplně
do všech podrobností, protože jak vyplývá z kvantové mechaniky, není možné určit zároveň polohu a rychlost
jednotlivých částic). Počítač může informaci, kterou má, různě přetvářet a analyzovat,
ale nemůže získat informaci o objektu na nižší úrovni, než jakou měl na vstupu
(bez dodatečných informací z vnějšku). Například jestliže chceme testovat na počítači reakci organismu
na nové léky, musíme vytvořit model a zadat podrobnosti na takové úrovni, jakou známe,
ale vždy to bude pouze zjednodušený model, který bude obsahovat jen takové podrobnosti, jaké jsme mu zadali.
A počítač nám může dát odpověď na to, jak se zachová náš model, ale ne jak se zachová skutečný organismus.

V druhém případě, kdy množina nul a jedniček odpovídá jiné množině nul a jedniček v počítači,
žádné jiné podrobnosti nejsou brány v úvahu (určitý rozsah napětí znamená nulu, a jiný znamená jedničku
a nerozlišuje se mezi menší jedničkou a trochu větší jedničkou). Nová informace, například součet nebo průměr,
se získává jen kombinací existujících nul a jedniček a můžeme najít nové vztahy a závislosti,
ale ne nové podrobnosti. Je dobře si též uvědomit, že k práci s informací není potřebné té informaci rozumět,
a to ani v případě, že se tvoří nová informace.

Podle naší definice informace, struktura, která může být i hodně složitá, sama o sobě není informací,
jestliže není nijak svázána s jinou strukturou nebo jevem. To znamená, že jestliže v počítači máme zapsány
nějaké řetězce nul a jedniček, které nesouvisí s žádnou strukturou nebo jevem,
pak tyto řetězce neobsahují žádnou informaci. Naopak, pokud víme, jaká je vazba mezi dvěma jevy,
může být pro nás užitečná informace i v tom, že jeden jev se stane úplně náhodný a bez žádné struktury.
Například šum na obrazovce televizoru nás informuje o tom, že je asi něco v nepořádku s anténou.

Jestliže máme dvě struktury, kde druhá struktura nás informuje o první, dovídáme se z té druhé vždy jen
o některých vlastnostech originálu. Tuto druhou strukturu můžeme v jistém smyslu považovat za jakýsi model
první struktury. Je zde vidět velice úzký vztah mezi informací a modelováním skutečnosti.
A právě modelováním skutečnosti se budeme zabývat v následující kapitole.

## [IV. Modelování skutečnosti](rozdzial4) -->
